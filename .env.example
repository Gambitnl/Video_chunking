# Optional API keys (leave empty to use local models only)
GROQ_API_KEY=
OPENAI_API_KEY=

# Model preferences
WHISPER_MODEL=large-v3
WHISPER_BACKEND=local  # Options: local, groq, openai
LLM_BACKEND=ollama  # Options: ollama, openai

# Processing settings
CHUNK_LENGTH_SECONDS=600
CHUNK_OVERLAP_SECONDS=10
AUDIO_SAMPLE_RATE=16000

# Audio snippet export
CLEAN_STALE_CLIPS=true  # Remove old snippet WAV clips before reprocessing

# Ollama settings (if using local LLM)
# Recommended models:
#   gpt-oss:20b  - OpenAI open-weight model, 12.8GB, 16GB RAM (BEST QUALITY)
#   qwen2.5:7b   - Best for Dutch, 4.7GB, 8GB RAM
#   llama3.2:3b  - Fastest, 2GB, 4GB RAM
#   llama3.1:8b  - Good balance, 4.7GB, 8GB RAM
OLLAMA_MODEL=gpt-oss:20b
OLLAMA_BASE_URL=http://localhost:11434
