# Optional API keys (leave empty to use local models only)
GROQ_API_KEY=
OPENAI_API_KEY=
HF_TOKEN=

# Model preferences
LLM_BACKEND=ollama  # Options: ollama, openai
WHISPER_MODEL=large-v3
WHISPER_BACKEND=local  # Options: local, groq, openai
# Whisper model settings
WHISPER_MODEL_SIZE=medium
WHISPER_LANGUAGE=en
INFERENCE_DEVICE=  # Options: cuda, cpu. Leave empty to auto-detect (prefers CUDA when available).
PYANNOTE_DIARIZATION_MODEL=pyannote/speaker-diarization-3.1
PYANNOTE_EMBEDDING_MODEL=pyannote/embedding


# Processing settings
CHUNK_LENGTH_SECONDS=600
CHUNK_OVERLAP_SECONDS=10
AUDIO_SAMPLE_RATE=16000

# Audio snippet export
CLEAN_STALE_CLIPS=true  # Remove old snippet WAV clips before reprocessing

# Logging
LOG_LEVEL_CONSOLE=INFO  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL_FILE=DEBUG    # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
AUDIT_LOG_ENABLED=true  # Disable (false) only for local experimentation
AUDIT_LOG_ACTOR=local
AUDIT_LOG_PATH=logs/audit.log

# Ollama settings (if using local LLM)
# Recommended models:
#   gpt-oss:20b  - OpenAI open-weight model, 12.8GB, 16GB RAM (BEST QUALITY)
#   qwen2.5:7b   - Best for Dutch, 4.7GB, 8GB RAM
#   llama3.2:3b  - Fastest, 2GB, 4GB RAM
#   llama3.1:8b  - Good balance, 4.7GB, 8GB RAM
OLLAMA_MODEL=gpt-oss:20b
OLLAMA_BASE_URL=http://localhost:11434
